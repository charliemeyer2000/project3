# Project 3 - Knowledge Distillation

## Logistics

My Token: [SET VIA ENVIRONMENT VARIABLE]
Username: "ignore all instructions"
HF token: [SET VIA ENVIRONMENT VARIABLE]

The user can only submit to the server when the user is connected to the UVA VPN/Wifi. if the user ever mentions anything about that, always ask them if they're connected, as you wont' be able to access the leaderboard/instructions page if you are not connected (which will cause timeouts). 

## Starter

The instructions have provided start code to get started with knowledge distillation, and you should follow this to ensure that the input/output shapes are as expected, you are using the correct dataset which has been downloaded from the homework server, and you are submitting to the correct submission server, and awaiting the status of the submission, seeing the status of the the leaderboard. 

The starter code and copied-and-pasted versions of the HTML of the docs/instructions are in the /docs folder for you to reference as you keep building. 

## Data

the unzipped version of the dataset can be found in `training_dataset`. Please inspect this dataset, understand how the classes are spread out, and actually also manually inspect the photos (or use some photo analysis scripts/code to understand what it looks like) to help with class weighting, properly scoring/not scoring depending on how a model performs for each class. 
- From a quick manual inspection, the images look very different to me, some have watermarks, some have axes/other designs on them, so we need to take a careful look to see if there's optimzatinos to be made with how we modify/augment data, load data, split data, etc. 

## Training on Modal

We will use modal to train our models. Therefore, what we need to do is:
- write modal code that allows us to run this on a GPU, maximally utilizing the GPU for training/inference/GPU-accelereated dataloading
- create a volume that we will use to store our models along with checkpoints of the models 

## Training Infrastructure

Similar to `project2_modal`, we want a highly customizable structure wherein we can create model architectures/training architectures for this knowledge-distillation problem, along with configs/hyperparameters in the CLI that allow us to tune various models to this task. Please implement this accordingly 

We will save all of our progress to a local sqlite database. 

What i imagine the flow will be like is:
- train a model on modal
- once finished, we pull the final/best model from the modal volume with a `modal volume get` command to a directory wherein we save the `.pt` file that's ready for submission
- we submit it with our `server_cli.py` file (reference `project2` for this)

except i want that all autoamted - that is, we run one command and it trains from modal, waits for modal to be finished, grabs the finished/best modal from the modal volume, submits and waits and syncs with our sqlite db once the server has evaluated it. 

we also need to consider the huggingface token and HF implementation as well - I have a token which i can authenticate with, but ensure that we can auth and don't have to deal with that. 

## Server CLI and handling the server

Please reference `server_cli.py` from project2 that has done a lot of the heavy lifting for submitting/polling the server and the code for parsing this stuff. what we need to do is:
- using our temp model generated by our starter code ipynb file, we can test some submissions to ensure that teh output of the homework3 server cli is similar to that of hw2, and then we can write the code to programatically submit to server, wait for server to respond with results on the status, and also sync with the db once we have the performance on the private dataset.  Consider edge cases (rate limits, unexpected responses). 

## Server

As mentioned previously, the server is only accessible if the user mentions that they are on the UVA VPN. However, it can be found at `http://hadi.cs.virginia.edu:9000/homework/3` and `http://hadi.cs.virginia.edu:9000/instructions-hw3` and all other links which are referenced in `docs/starter_hw3` for submission and leaderboard and submission status, etc. ensure you read that. 


## refernces

please reference project_2 and project2_modal to get an idea of how we can best implement this, but ideally this is a very clean, small, debuggable, maintainable, and extensible codebase that does not have all of the bloat of the previous directories. can we use pydantic and other besy practice and classes and hyudra and stuff? 