# Fast training configuration (for quick experiments)

epochs: 20
optimizer: Adam
learning_rate: 0.001
weight_decay: 0.0001
grad_clip: 1.0

scheduler:
  type: StepLR
  step_size: 10
  gamma: 0.1

early_stopping:
  enabled: true
  patience: 5
  metric: val_f1_macro

checkpoint:
  save_best_only: true
  monitor: val_f1_macro

